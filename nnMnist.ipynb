{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "# import keras\n",
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAABHdJREFUeJzt3TFOlF0UgGHnz4SEjsYEG21lCRTEWNGzC5fgJihZB8E90BFKaChoiIUmUBG0GLu/gov6wYzhfZ5yTsa5Cb45CTcfM1ssFq+Al++/VR8AWA6xQ4TYIULsECF2iJgv+fP86h+e3+y+F212iBA7RIgdIsQOEWKHCLFDhNghQuwQIXaIEDtEiB0ixA4RYocIsUOE2CFC7BAhdogQO0SIHSLEDhFihwixQ4TYIULsECF2iBA7RIgdIsQOEWKHCLFDhNghQuwQIXaIEDtEiB0ixA4RYocIsUPEfNUH4Hn9/PlzOD8+Ph7OP3/+POn9/DtsdogQO0SIHSLEDhFihwixQ4TYIWK2WCyW+XlL/TBevfr27dtw/vr16+F8c3NzOD89PZ30fp7F7L4XbXaIEDtEiB0ixA4RYocIsUOER1wZ+vr166S5q7d/h80OEWKHCLFDhNghQuwQIXaIEDtEiB0ixA4RYocIsUOE2CFC7BAhdogQO0R4np1Jbm9vV30EfpPNDhFihwixQ4TYIULsECF2iBA7RLhnZ5KTk5PhfHt7e0kn4TE2O0SIHSLEDhFihwixQ4TYIULsEOGe/YWbz8c/4o2NjeH8+vp6OL+4uPjjM7EaNjtEiB0ixA4RYocIsUOE2CHC1dsL99jV2s7OznD+5cuXpzwOK2SzQ4TYIULsECF2iBA7RIgdIsQOEWKHCLFDhNghQuwQIXaIEDtEiB0ixA4Rnmdnku/fv6/6CPwmmx0ixA4RYocIsUOE2CFC7BAhdohwz84kR0dHqz4Cv8lmhwixQ4TYIULsECF2iBA7RIgdItyzx338+HE49/3sL4fNDhFihwixQ4TYIULsECF2iHD1Fvf27dtJ7//x48dwfnl5+eDs3bt3kz6bP2OzQ4TYIULsECF2iBA7RIgdIsQOEe7Z4+bzaf8FFovFcH53dzfp3+fp2OwQIXaIEDtEiB0ixA4RYocIsUPE7LF70ie21A9juq2treH8/Px8OP/06dODs4ODg786E4+a3feizQ4RYocIsUOE2CFC7BAhdogQO0R4np2h3d3d4fzq6mo439/ff8rjMIHNDhFihwixQ4TYIULsECF2iHD1xiSz2b1PU/5vbW1tSSfhMTY7RIgdIsQOEWKHCLFDhNghQuwQ4Z6dSW5ubobzw8PDB2d7e3tPfRwGbHaIEDtEiB0ixA4RYocIsUOE2CHCVzYz9ObNm+H8+vp6OD89PX1w9v79+786E4/ylc1QJnaIEDtEiB0ixA4RYocIsUOE59kZ+vDhw3B+dnY2nK+vrz/lcZjAZocIsUOE2CFC7BAhdogQO0SIHSI8zw4vj+fZoUzsECF2iBA7RIgdIsQOEWKHCLFDhNghQuwQIXaIEDtEiB0ixA4RYocIsUOE2CFC7BAhdogQO0SIHSLEDhHL/srme//ELfD8bHaIEDtEiB0ixA4RYocIsUOE2CFC7BAhdogQO0SIHSLEDhFihwixQ4TYIULsECF2iBA7RIgdIsQOEWKHCLFDhNgh4hdEKmfD6e9v1AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "i = 8\n",
    "plt.imshow(x_train[i,:], cmap = matplotlib.cm.binary)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "print(y_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the images\n",
    "\n",
    "image_vector_size = 28*28\n",
    "\n",
    "X_train = x_train.reshape(x_train.shape[0],image_vector_size)\n",
    "\n",
    "X_test = x_test.reshape( x_test.shape[0],image_vector_size)\n",
    "X_train=X_train.T\n",
    "X_test=X_test.T\n",
    "# scale\n",
    "X_train = X_train / 255\n",
    "X_test = X_test/ 255\n",
    "\n",
    "\n",
    "# one-hot encode labels\n",
    "# Convert to \"one-hot\" vectors using the to_categorical function\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "Y_train=y_train.T\n",
    "\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "y_test=y_test.T\n",
    "Y_test=y_test\n",
    "\n",
    "# split, reshape, shuffle\n",
    "m = 60000\n",
    "#m_test = X.shape[0] - m\n",
    "shuffle_index = np.random.permutation(m)\n",
    "X_train, Y_train = X_train[:, shuffle_index], Y_train[:, shuffle_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "i = 8\n",
    "plt.imshow(X_train[:,i].reshape(28,28), cmap = matplotlib.cm.binary)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "print(Y_train[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sigmoid(z):\n",
    "    s = 1. / (1. + np.exp(-z))\n",
    "    return s\n",
    "\n",
    "def compute_loss(Y, Y_hat):\n",
    "\n",
    "    L_sum = np.sum(np.multiply(Y, np.log(Y_hat)))\n",
    "    m = Y.shape[1]\n",
    "    L = -(1./m) * L_sum\n",
    "\n",
    "    return L\n",
    "\n",
    "def feed_forward(X, params):\n",
    "\n",
    "    cache = {}\n",
    "\n",
    "    cache[\"Z1\"] = np.matmul(params[\"W1\"], X) + params[\"b1\"]\n",
    "    cache[\"A1\"] = sigmoid(cache[\"Z1\"])\n",
    "    cache[\"Z2\"] = np.matmul(params[\"W2\"], cache[\"A1\"]) + params[\"b2\"]\n",
    "    cache[\"A2\"] = np.exp(cache[\"Z2\"]) / np.sum(np.exp(cache[\"Z2\"]), axis=0)\n",
    "\n",
    "    return cache\n",
    "\n",
    "def back_propagate(X, Y, params, cache):\n",
    "\n",
    "    dZ2 = cache[\"A2\"] - Y\n",
    "    dW2 = (1./m_batch) * np.matmul(dZ2, cache[\"A1\"].T)\n",
    "    db2 = (1./m_batch) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "\n",
    "    dA1 = np.matmul(params[\"W2\"].T, dZ2)\n",
    "    dZ1 = dA1 * sigmoid(cache[\"Z1\"]) * (1 - sigmoid(cache[\"Z1\"]))\n",
    "    dW1 = (1./m_batch) * np.matmul(dZ1, X.T)\n",
    "    db1 = (1./m_batch) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "\n",
    "    grads = {\"dW1\": dW1, \"db1\": db1, \"dW2\": dW2, \"db2\": db2}\n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: training cost = 0.14708906052963197, test cost = 0.14801820887572031\n",
      "Epoch 2: training cost = 0.10450601443362853, test cost = 0.12418992991227168\n",
      "Epoch 3: training cost = 0.08336427012072614, test cost = 0.1090139950935264\n",
      "Epoch 4: training cost = 0.06392012491597363, test cost = 0.09964337223829581\n",
      "Epoch 5: training cost = 0.04966232987203544, test cost = 0.08526880050298048\n",
      "Epoch 6: training cost = 0.043871188028556246, test cost = 0.08266443131351806\n",
      "Epoch 7: training cost = 0.034285074964919324, test cost = 0.08330903361492598\n",
      "Epoch 8: training cost = 0.036003389250708, test cost = 0.08427328712938133\n",
      "Epoch 9: training cost = 0.02748569152464696, test cost = 0.08173574331692461\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "np.random.seed(138)\n",
    "digits=10;\n",
    "# hyperparameters\n",
    "n_x = X_train.shape[0]\n",
    "n_h = 64\n",
    "learning_rate = 4\n",
    "beta = .9\n",
    "batch_size = 128\n",
    "batches = -(-m // batch_size)\n",
    "\n",
    "# initialization\n",
    "params = { \"W1\": np.random.randn(n_h, n_x) * np.sqrt(1. / n_x),\n",
    "           \"b1\": np.zeros((n_h, 1)) * np.sqrt(1. / n_x),\n",
    "           \"W2\": np.random.randn(digits, n_h) * np.sqrt(1. / n_h),\n",
    "           \"b2\": np.zeros((digits, 1)) * np.sqrt(1. / n_h) }\n",
    "\n",
    "V_dW1 = np.zeros(params[\"W1\"].shape)\n",
    "V_db1 = np.zeros(params[\"b1\"].shape)\n",
    "V_dW2 = np.zeros(params[\"W2\"].shape)\n",
    "V_db2 = np.zeros(params[\"b2\"].shape)\n",
    "\n",
    "# train\n",
    "for i in range(9):\n",
    "\n",
    "    permutation = np.random.permutation(X_train.shape[1])\n",
    "    X_train_shuffled = X_train[:, permutation]\n",
    "    Y_train_shuffled = Y_train[:, permutation]\n",
    "\n",
    "    for j in range(batches):\n",
    "\n",
    "        begin = j * batch_size\n",
    "        end = min(begin + batch_size, X_train.shape[1] - 1)\n",
    "        X = X_train_shuffled[:, begin:end]\n",
    "        Y = Y_train_shuffled[:, begin:end]\n",
    "        m_batch = end - begin\n",
    "\n",
    "        cache = feed_forward(X, params)\n",
    "        grads = back_propagate(X, Y, params, cache)\n",
    "\n",
    "        V_dW1 = (beta * V_dW1 + (1. - beta) * grads[\"dW1\"])\n",
    "        V_db1 = (beta * V_db1 + (1. - beta) * grads[\"db1\"])\n",
    "        V_dW2 = (beta * V_dW2 + (1. - beta) * grads[\"dW2\"])\n",
    "        V_db2 = (beta * V_db2 + (1. - beta) * grads[\"db2\"])\n",
    "\n",
    "        params[\"W1\"] = params[\"W1\"] - learning_rate * V_dW1\n",
    "        params[\"b1\"] = params[\"b1\"] - learning_rate * V_db1\n",
    "        params[\"W2\"] = params[\"W2\"] - learning_rate * V_dW2\n",
    "        params[\"b2\"] = params[\"b2\"] - learning_rate * V_db2\n",
    "\n",
    "    cache = feed_forward(X_train, params)\n",
    "    train_cost = compute_loss(Y_train, cache[\"A2\"])\n",
    "    cache = feed_forward(X_test, params)\n",
    "    test_cost = compute_loss(Y_test, cache[\"A2\"])\n",
    "    print(\"Epoch {}: training cost = {}, test cost = {}\".format(i+1 ,train_cost, test_cost))\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       989\n",
      "           1       0.99      0.99      0.99      1136\n",
      "           2       0.98      0.98      0.98      1025\n",
      "           3       0.97      0.96      0.97      1025\n",
      "           4       0.98      0.98      0.98       979\n",
      "           5       0.98      0.96      0.97       907\n",
      "           6       0.98      0.98      0.98       954\n",
      "           7       0.98      0.97      0.98      1030\n",
      "           8       0.96      0.99      0.97       948\n",
      "           9       0.97      0.97      0.97      1007\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     10000\n",
      "   macro avg       0.98      0.98      0.98     10000\n",
      "weighted avg       0.98      0.98      0.98     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cache = feed_forward(X_test, params)\n",
    "predictions = np.argmax(cache[\"A2\"], axis=0)\n",
    "labels = np.argmax(Y_test, axis=0)\n",
    "\n",
    "print(classification_report(predictions, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
